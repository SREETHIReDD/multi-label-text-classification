{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oaYbWIY0Geh",
        "outputId": "688cc081-2c58-4c5f-bd54-c10215004dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "# Colab Notebook Template for Multi-Label Text Classification Pipeline\n",
        "\n",
        "# --- 1. Setup and Installations ---\n",
        "!pip install transformers datasets scikit-learn pandas seaborn nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Generate Synthetic Data ---\n",
        "def generate_synthetic_data():\n",
        "    # Define the domain knowledge\n",
        "    domain_knowledge = {\n",
        "        \"competitors\": [\"CompetitorX\", \"CompetitorY\", \"CompetitorZ\"],\n",
        "        \"features\": [\"analytics\", \"AI engine\", \"data pipeline\"],\n",
        "        \"pricing_keywords\": [\"discount\", \"renewal cost\", \"budget\", \"pricing model\"]\n",
        "    }\n",
        "\n",
        "    # Save domain knowledge as JSON\n",
        "    with open('domain_knowledge.json', 'w') as f:\n",
        "        json.dump(domain_knowledge, f, indent=4)\n",
        "\n",
        "    # Generate calls dataset\n",
        "    data = []\n",
        "    for i in range(1, 101):\n",
        "        snippet = f\"This is a sample call snippet discussing {np.random.choice(domain_knowledge['features'])} and {np.random.choice(domain_knowledge['pricing_keywords'])}.\"\n",
        "        labels = np.random.choice([\"Objection\", \"Pricing Discussion\", \"Security\", \"Competition\"], size=np.random.randint(1, 4), replace=False)\n",
        "        data.append({\"id\": i, \"text_snippet\": snippet, \"labels\": \",\".join(labels)})\n",
        "\n",
        "    # Convert to DataFrame and save as CSV\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv('calls_dataset.csv', index=False)\n",
        "    return df\n",
        "\n",
        "data = generate_synthetic_data()\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lZENPmGOGbFn",
        "outputId": "ae7453db-ff1d-44ad-a7eb-c543b2ca9302"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                       text_snippet  \\\n",
              "0   1  This is a sample call snippet discussing AI en...   \n",
              "1   2  This is a sample call snippet discussing AI en...   \n",
              "2   3  This is a sample call snippet discussing data ...   \n",
              "3   4  This is a sample call snippet discussing AI en...   \n",
              "4   5  This is a sample call snippet discussing AI en...   \n",
              "\n",
              "                                  labels  \n",
              "0                     Pricing Discussion  \n",
              "1                            Competition  \n",
              "2         Security,Objection,Competition  \n",
              "3  Objection,Pricing Discussion,Security  \n",
              "4         Objection,Security,Competition  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f91e9b4d-f4b0-418f-99a4-0a1f74a1a6d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_snippet</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>This is a sample call snippet discussing AI en...</td>\n",
              "      <td>Pricing Discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is a sample call snippet discussing AI en...</td>\n",
              "      <td>Competition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>This is a sample call snippet discussing data ...</td>\n",
              "      <td>Security,Objection,Competition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>This is a sample call snippet discussing AI en...</td>\n",
              "      <td>Objection,Pricing Discussion,Security</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>This is a sample call snippet discussing AI en...</td>\n",
              "      <td>Objection,Security,Competition</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f91e9b4d-f4b0-418f-99a4-0a1f74a1a6d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f91e9b4d-f4b0-418f-99a4-0a1f74a1a6d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f91e9b4d-f4b0-418f-99a4-0a1f74a1a6d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-274efcc9-7537-42e8-93a3-8d4cae839739\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-274efcc9-7537-42e8-93a3-8d4cae839739')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-274efcc9-7537-42e8-93a3-8d4cae839739 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 1,\n        \"max\": 100,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          84,\n          54,\n          71\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_snippet\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"This is a sample call snippet discussing analytics and budget.\",\n          \"This is a sample call snippet discussing AI engine and pricing model.\",\n          \"This is a sample call snippet discussing AI engine and discount.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"Pricing Discussion,Competition,Security\",\n          \"Competition,Objection,Pricing Discussion\",\n          \"Competition,Objection,Security\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Data Preprocessing with spaCy ---\n",
        "!pip install spacy -q\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load spaCy's English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Preprocessing function using spaCy\n",
        "def preprocess_text_spacy(text):\n",
        "    doc = nlp(text.lower())\n",
        "    # Filter tokens: alphabetic, not stopwords, and not punctuation\n",
        "    words = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Apply preprocessing\n",
        "data['cleaned_text'] = data['text_snippet'].apply(preprocess_text_spacy)\n",
        "\n",
        "# Display the first few rows\n",
        "data.head()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['labels'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OuzsbjfYniLY",
        "outputId": "45761105-3d85-4159-977f-bf3163c8b5db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-31c9eb87dc4a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Split the dataset into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_namespace_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \"\"\"\n\u001b[1;32m   1908\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1909\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2319\u001b[0m                 \u001b[0;34m\"The least populated class in y has only 1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import spacy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load spaCy's English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Preprocessing function using spaCy\n",
        "def preprocess_text_spacy(text):\n",
        "    doc = nlp(text.lower())\n",
        "    # Filter tokens: alphabetic, not stopwords, and not punctuation\n",
        "    words = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Apply preprocessing\n",
        "data['cleaned_text'] = data['text_snippet'].apply(preprocess_text_spacy)\n",
        "\n",
        "# Filter data to ensure each class has at least two instances\n",
        "data['labels_split'] = data['labels'].str.split(',')  # Split multi-label column into lists\n",
        "data = data.explode('labels_split')  # Expand multi-label rows\n",
        "label_counts = data['labels_split'].value_counts()  # Count occurrences of each label\n",
        "valid_labels = label_counts[label_counts > 1].index  # Keep only labels with >1 instance\n",
        "data = data[data['labels_split'].isin(valid_labels)]  # Filter the dataset\n",
        "\n",
        "# Recombine labels for multi-label format\n",
        "data = data.groupby('id').agg({\n",
        "    'text_snippet': 'first',\n",
        "    'cleaned_text': 'first',\n",
        "    'labels_split': lambda x: ','.join(sorted(set(x)))\n",
        "}).reset_index()\n",
        "\n",
        "# Split the dataset\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['labels_split'])\n"
      ],
      "metadata": {
        "id": "jfvIwD6yprxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Define Dataset Class for Transformers ---\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, label_map, max_length):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_map = label_map\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.data.iloc[index]['cleaned_text']\n",
        "        labels = self.data.iloc[index]['labels'].split(',')\n",
        "        label_vector = [0] * len(self.label_map)\n",
        "        for label in labels:\n",
        "            label_vector[self.label_map[label]] = 1\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(label_vector, dtype=torch.float)\n",
        "        }"
      ],
      "metadata": {
        "id": "OAYEesflp1us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Model Training ---\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4, problem_type=\"multi_label_classification\")\n",
        "\n",
        "# Map labels to integers\n",
        "unique_labels = sorted(set(\",\".join(data['labels']).split(',')))\n",
        "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = MultiLabelDataset(train_data, tokenizer, label_map, max_length=128)\n",
        "test_dataset = MultiLabelDataset(test_data, tokenizer, label_map, max_length=128)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        ")\n",
        "\n",
        "# Define compute metrics\n",
        "def compute_metrics(pred):\n",
        "    from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "    logits, labels = pred\n",
        "    predictions = (logits > 0.5).astype(int)\n",
        "    precision = precision_score(labels, predictions, average='micro')\n",
        "    recall = recall_score(labels, predictions, average='micro')\n",
        "    f1 = f1_score(labels, predictions, average='micro')\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "D3rCFtjSp1zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Generate Synthetic Data ---\n",
        "def generate_synthetic_data():\n",
        "    # Define the domain knowledge\n",
        "    domain_knowledge = {\n",
        "        \"competitors\": [\"CompetitorX\", \"CompetitorY\", \"CompetitorZ\"],\n",
        "        \"features\": [\"analytics\", \"AI engine\", \"data pipeline\"],\n",
        "        \"pricing_keywords\": [\"discount\", \"renewal cost\", \"budget\", \"pricing model\"]\n",
        "    }\n",
        "\n",
        "    # Save domain knowledge as JSON\n",
        "    with open('domain_knowledge.json', 'w') as f:\n",
        "        json.dump(domain_knowledge, f, indent=4)\n",
        "\n",
        "    # Generate calls dataset\n",
        "    data = []\n",
        "    for i in range(1, 101):\n",
        "        snippet = f\"This is a sample call snippet discussing {np.random.choice(domain_knowledge['features'])} and {np.random.choice(domain_knowledge['pricing_keywords'])}.\"\n",
        "        labels = np.random.choice([\"Objection\", \"Pricing Discussion\", \"Security\", \"Competition\"], size=np.random.randint(1, 4), replace=False)\n",
        "        data.append({\"id\": i, \"text_snippet\": snippet, \"labels\": \",\".join(labels)})\n",
        "\n",
        "    # Convert to DataFrame and save as CSV\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv('calls_dataset.csv', index=False)\n",
        "    return df\n",
        "\n",
        "data = generate_synthetic_data()\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r6Onj46CF5pC",
        "outputId": "76730e09-d1b9-4fdf-cbe8-bdb00acc3051"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                       text_snippet  \\\n",
              "0   1  This is a sample call snippet discussing analy...   \n",
              "1   2  This is a sample call snippet discussing data ...   \n",
              "2   3  This is a sample call snippet discussing analy...   \n",
              "3   4  This is a sample call snippet discussing analy...   \n",
              "4   5  This is a sample call snippet discussing analy...   \n",
              "\n",
              "                                    labels  \n",
              "0                       Pricing Discussion  \n",
              "1  Security,Competition,Pricing Discussion  \n",
              "2                       Security,Objection  \n",
              "3           Competition,Pricing Discussion  \n",
              "4  Security,Competition,Pricing Discussion  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53a0a168-4acc-4a8b-ae39-8f37a297ea30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_snippet</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>This is a sample call snippet discussing analy...</td>\n",
              "      <td>Pricing Discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is a sample call snippet discussing data ...</td>\n",
              "      <td>Security,Competition,Pricing Discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>This is a sample call snippet discussing analy...</td>\n",
              "      <td>Security,Objection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>This is a sample call snippet discussing analy...</td>\n",
              "      <td>Competition,Pricing Discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>This is a sample call snippet discussing analy...</td>\n",
              "      <td>Security,Competition,Pricing Discussion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53a0a168-4acc-4a8b-ae39-8f37a297ea30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53a0a168-4acc-4a8b-ae39-8f37a297ea30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53a0a168-4acc-4a8b-ae39-8f37a297ea30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-778ca97a-dc63-4f65-9349-a6f8f8b34d19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-778ca97a-dc63-4f65-9349-a6f8f8b34d19')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-778ca97a-dc63-4f65-9349-a6f8f8b34d19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 1,\n        \"max\": 100,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          84,\n          54,\n          71\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_snippet\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"This is a sample call snippet discussing AI engine and discount.\",\n          \"This is a sample call snippet discussing data pipeline and renewal cost.\",\n          \"This is a sample call snippet discussing analytics and discount.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"Objection,Pricing Discussion,Competition\",\n          \"Pricing Discussion,Competition\",\n          \"Competition,Security,Pricing Discussion\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download spaCy model\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1OUETLUsv5F",
        "outputId": "9d826fcb-27b3-4bbc-f4fb-ea6070564715"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Data Preprocessing ---\n",
        "# Load spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())  # Process the text with spaCy\n",
        "    # Remove stopwords and non-alphanumeric characters\n",
        "    words = [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Apply preprocessing\n",
        "data['cleaned_text'] = data['text_snippet'].apply(preprocess_text)\n",
        "\n",
        "# Ensure each label has at least two samples\n",
        "label_counts = data['labels'].value_counts()\n",
        "valid_labels = label_counts[label_counts > 1].index\n",
        "filtered_data = data[data['labels'].isin(valid_labels)]\n",
        "\n",
        "# Validate test_size dynamically\n",
        "min_test_samples = len(filtered_data['labels'].unique())  # Minimum samples needed for stratification\n",
        "if len(filtered_data) < min_test_samples * 2:  # Check if the dataset is too small\n",
        "    raise ValueError(\n",
        "        f\"Not enough samples to split: {len(filtered_data)} samples for {min_test_samples} classes. \"\n",
        "        \"Ensure at least two samples per class.\"\n",
        "    )\n",
        "\n",
        "# Set test_size as a proportion, ensuring the test set has enough samples\n",
        "test_size = max(0.2, min(0.5, min_test_samples / len(filtered_data)))\n",
        "\n",
        "# Split the filtered dataset\n",
        "train_data, test_data = train_test_split(\n",
        "    filtered_data,\n",
        "    test_size=test_size,\n",
        "    stratify=filtered_data['labels']\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}, Test samples: {len(test_data)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psVDFFKrtrOK",
        "outputId": "17cc7c9d-5fba-4c18-fe70-bf3d7e0589f2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 67, Test samples: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Define Dataset Class for Transformers ---\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, label_map, max_length):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_map = label_map\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.data.iloc[index]['cleaned_text']\n",
        "        labels = self.data.iloc[index]['labels'].split(',')\n",
        "        label_vector = [0] * len(self.label_map)\n",
        "        for label in labels:\n",
        "            label_vector[self.label_map[label]] = 1\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(label_vector, dtype=torch.float)\n",
        "        }"
      ],
      "metadata": {
        "id": "UDRP97ovtZDO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Model Training ---\n",
        "\n",
        "import warnings\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Suppress the Hugging Face warning related to the API key\n",
        "warnings.filterwarnings(\"ignore\", message=\".*does not exist in your Colab secrets.*\")\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=4,\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "# Map labels to integers\n",
        "unique_labels = sorted(set(\",\".join(data['labels']).split(',')))\n",
        "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = MultiLabelDataset(train_data, tokenizer, label_map, max_length=128)\n",
        "test_dataset = MultiLabelDataset(test_data, tokenizer, label_map, max_length=128)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",  # Save the model at the end of each epoch\n",
        "    learning_rate=5e-5,  # Increased learning rate for faster learning\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=10,  # Increased epochs for better convergence\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,  # Keep only the 2 most recent saved models\n",
        "    load_best_model_at_end=True,  # Load the best model based on evaluation metric\n",
        "    metric_for_best_model=\"f1\",  # Use F1 score to identify the best model\n",
        "    lr_scheduler_type=\"linear\",  # Linear learning rate scheduler\n",
        "    warmup_steps=500,  # Gradual increase in learning rate\n",
        "    report_to=\"none\",  # Disable W&B logging\n",
        ")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    logits, labels = pred\n",
        "\n",
        "    # Apply sigmoid activation to scale logits to probabilities\n",
        "    probabilities = 1 / (1 + np.exp(-logits))  # Sigmoid function\n",
        "\n",
        "    # Use a threshold of 0.5 for multi-label classification\n",
        "    predictions = (probabilities > 0.5).astype(int)\n",
        "\n",
        "    # Debugging information\n",
        "    print(\"Logits Distribution (mean ± std):\", np.mean(logits), \"±\", np.std(logits))\n",
        "    print(\"Logits (First 5 Rows):\\n\", logits[:5])\n",
        "    print(\"Probabilities (First 5 Rows):\\n\", probabilities[:5])  # Display probabilities\n",
        "    print(\"Predictions (First 5 Rows):\\n\", predictions[:5])\n",
        "    print(\"Labels (First 5 Rows):\\n\", labels[:5])\n",
        "\n",
        "    # Calculate metrics, handling undefined precision/recall with zero_division\n",
        "    precision = precision_score(labels, predictions, average='micro', zero_division=0)\n",
        "    recall = recall_score(labels, predictions, average='micro', zero_division=0)\n",
        "    f1 = f1_score(labels, predictions, average='micro', zero_division=0)\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "\n",
        "# Loss function with pos_weight (for handling class imbalance if needed)\n",
        "# Uncomment if you want to handle class imbalance.\n",
        "# from torch.nn import BCEWithLogitsLoss\n",
        "# class_weights = torch.tensor([1.5, 1.0, 2.0, 1.2])  # Example weights (adjust based on your dataset)\n",
        "# model.config.loss = BCEWithLogitsLoss(pos_weight=class_weights)\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4EZUBNnqvc5X",
        "outputId": "df553dc0-837d-424d-8db3-2937d155de4e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [90/90 21:07, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.717995</td>\n",
              "      <td>0.456522</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.477273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.714642</td>\n",
              "      <td>0.456522</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.477273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.709890</td>\n",
              "      <td>0.456522</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.477273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.703801</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.389610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.699993</td>\n",
              "      <td>0.441176</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.394737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.701756</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.709240</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.261905</td>\n",
              "      <td>0.328358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.722249</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.725901</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.409091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.725112</td>\n",
              "      <td>0.435897</td>\n",
              "      <td>0.404762</td>\n",
              "      <td>0.419753</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits Distribution (mean ± std): 0.03221993 ± 0.40502295\n",
            "Logits (First 5 Rows):\n",
            " [[ 0.558419   -0.23012756 -0.42872444  0.19110355]\n",
            " [ 0.558419   -0.23012756 -0.42872444  0.19110355]\n",
            " [ 0.59202385 -0.2959283  -0.43018317  0.24730423]\n",
            " [ 0.5644435  -0.2671002  -0.46082866  0.32615334]\n",
            " [ 0.58744705 -0.28118682 -0.4484228   0.21871197]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.6360867  0.44272068 0.39443097 0.547631  ]\n",
            " [0.6360867  0.44272068 0.39443097 0.547631  ]\n",
            " [0.64382935 0.42655316 0.3940826  0.5615129 ]\n",
            " [0.6374801  0.4336191  0.38678926 0.5808231 ]\n",
            " [0.64277923 0.43016288 0.38973582 0.55446106]]\n",
            "Predictions (First 5 Rows):\n",
            " [[1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "Logits Distribution (mean ± std): 0.0113190105 ± 0.3820246\n",
            "Logits (First 5 Rows):\n",
            " [[ 0.53230166 -0.25471294 -0.39467826  0.10742597]\n",
            " [ 0.53230166 -0.25471294 -0.39467826  0.10742597]\n",
            " [ 0.5658939  -0.30524576 -0.40013283  0.18353307]\n",
            " [ 0.54657805 -0.28820723 -0.4398504   0.26328346]\n",
            " [ 0.56135094 -0.2966418  -0.41746077  0.14606106]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.6300198  0.43666378 0.40259162 0.5268307 ]\n",
            " [0.6300198  0.43666378 0.40259162 0.5268307 ]\n",
            " [0.6378152  0.42427564 0.40128043 0.5457549 ]\n",
            " [0.6333413  0.42844287 0.39177662 0.5654433 ]\n",
            " [0.63676506 0.42637864 0.39712456 0.53645045]]\n",
            "Predictions (First 5 Rows):\n",
            " [[1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "Logits Distribution (mean ± std): 0.0044330577 ± 0.3285769\n",
            "Logits (First 5 Rows):\n",
            " [[ 0.45480013 -0.22717015 -0.3222818   0.03225414]\n",
            " [ 0.45480013 -0.22717015 -0.3222818   0.03225414]\n",
            " [ 0.5027037  -0.27236828 -0.3425759   0.14783435]\n",
            " [ 0.492637   -0.2463237  -0.39545447  0.22220501]\n",
            " [ 0.49158138 -0.26329345 -0.3555305   0.08485563]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.6117799  0.44345042 0.42011973 0.50806284]\n",
            " [0.6117799  0.44345042 0.42011973 0.50806284]\n",
            " [0.6230945  0.43232578 0.4151839  0.5368914 ]\n",
            " [0.6207274  0.43872857 0.40240496 0.5553238 ]\n",
            " [0.6204789  0.43455428 0.41204196 0.5212012 ]]\n",
            "Predictions (First 5 Rows):\n",
            " [[1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "Logits Distribution (mean ± std): -0.008034417 ± 0.23311315\n",
            "Logits (First 5 Rows):\n",
            " [[ 0.3225395  -0.21040303 -0.18950573 -0.08087625]\n",
            " [ 0.3225395  -0.21040303 -0.18950573 -0.08087625]\n",
            " [ 0.38635212 -0.2266544  -0.22400281  0.09606444]\n",
            " [ 0.37973607 -0.15960407 -0.28553987  0.13854551]\n",
            " [ 0.36094105 -0.22398116 -0.23187503 -0.0068166 ]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.579943   0.44759244 0.45276484 0.47979197]\n",
            " [0.579943   0.44759244 0.45276484 0.47979197]\n",
            " [0.5954042  0.4435777  0.44423226 0.52399766]\n",
            " [0.5938094  0.4601835  0.42909613 0.53458107]\n",
            " [0.5892682  0.44423765 0.44228962 0.4982959 ]]\n",
            "Predictions (First 5 Rows):\n",
            " [[1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 0]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "Logits Distribution (mean ± std): -0.04061546 ± 0.15128893\n",
            "Logits (First 5 Rows):\n",
            " [[ 0.13890481 -0.2050175  -0.03597175 -0.25249448]\n",
            " [ 0.13890481 -0.2050175  -0.03597175 -0.25249448]\n",
            " [ 0.23267311 -0.17558852 -0.09105045  0.04994602]\n",
            " [ 0.22453347 -0.09678946 -0.14483102  0.02705166]\n",
            " [ 0.16030836 -0.19644992 -0.06165136 -0.16471425]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.5346705  0.44892436 0.491008   0.4372096 ]\n",
            " [0.5346705  0.44892436 0.491008   0.4372096 ]\n",
            " [0.5579073  0.45621532 0.4772531  0.5124839 ]\n",
            " [0.5558987  0.47582152 0.46385542 0.5067625 ]\n",
            " [0.5399915  0.45104486 0.48459205 0.45891428]]\n",
            "Predictions (First 5 Rows):\n",
            " [[1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 0]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "Logits Distribution (mean ± std): -0.12288865 ± 0.20786762\n",
            "Logits (First 5 Rows):\n",
            " [[-6.3256823e-02 -2.1478572e-01  8.2035810e-02 -5.1601970e-01]\n",
            " [-6.3256823e-02 -2.1478572e-01  8.2035810e-02 -5.1601970e-01]\n",
            " [ 8.8011622e-02 -2.5797474e-01  2.7278066e-04 -1.2526491e-01]\n",
            " [ 2.5583901e-02 -1.2624778e-01  2.5748014e-03 -1.5418848e-01]\n",
            " [-1.2296633e-01 -1.6757306e-01  1.3635066e-01 -4.5217732e-01]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.48419106 0.44650903 0.52049744 0.37378344]\n",
            " [0.48419106 0.44650903 0.52049744 0.37378344]\n",
            " [0.5219887  0.4358616  0.5000682  0.46872467]\n",
            " [0.50639564 0.46847987 0.5006437  0.46152905]\n",
            " [0.46929705 0.45820448 0.53403497 0.3888432 ]]\n",
            "Predictions (First 5 Rows):\n",
            " [[0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [1 0 1 0]\n",
            " [1 0 1 0]\n",
            " [0 0 1 0]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "Logits Distribution (mean ± std): -0.16855896 ± 0.28054854\n",
            "Logits (First 5 Rows):\n",
            " [[-0.1406906  -0.23457643  0.0938105  -0.65684634]\n",
            " [-0.1406906  -0.23457643  0.0938105  -0.65684634]\n",
            " [ 0.11843435 -0.36640182 -0.06140134 -0.09761251]\n",
            " [-0.07202323 -0.16672416  0.05625454 -0.16120234]\n",
            " [-0.26086968 -0.14933693  0.20661375 -0.62498647]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.46488526 0.4416233  0.5234354  0.3414484 ]\n",
            " [0.46488526 0.4416233  0.5234354  0.3414484 ]\n",
            " [0.52957404 0.40941077 0.48465452 0.47561622]\n",
            " [0.48200196 0.4584152  0.5140599  0.45978644]\n",
            " [0.43514994 0.462735   0.55147046 0.3486482 ]]\n",
            "Predictions (First 5 Rows):\n",
            " [[0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [1 0 0 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "Logits Distribution (mean ± std): -0.11603148 ± 0.31842428\n",
            "Logits (First 5 Rows):\n",
            " [[-0.24638517 -0.22900431  0.10339557 -0.6965553 ]\n",
            " [-0.24638517 -0.22900431  0.10339557 -0.6965553 ]\n",
            " [ 0.03940364 -0.3381586  -0.05551091  0.12619734]\n",
            " [-0.19376823 -0.07362792  0.11868969 -0.02382204]\n",
            " [-0.4407822  -0.12095699  0.26267964 -0.6564105 ]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.43871343 0.44299778 0.5258259  0.3325764 ]\n",
            " [0.43871343 0.44299778 0.5258259  0.3325764 ]\n",
            " [0.5098496  0.41625684 0.48612586 0.53150755]\n",
            " [0.45170897 0.48160133 0.52963763 0.4940448 ]\n",
            " [0.39155462 0.46979758 0.5652949  0.34154642]]\n",
            "Predictions (First 5 Rows):\n",
            " [[0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [1 0 0 1]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "Logits Distribution (mean ± std): -0.06490508 ± 0.33646533\n",
            "Logits (First 5 Rows):\n",
            " [[-0.18783836 -0.34332386  0.03810281 -0.5546578 ]\n",
            " [-0.18783836 -0.34332386  0.03810281 -0.5546578 ]\n",
            " [ 0.09121682 -0.2353963  -0.09929007  0.48501542]\n",
            " [-0.21977143  0.09940012  0.15296859  0.23121387]\n",
            " [-0.34576583 -0.23267838  0.13842309 -0.3534937 ]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.45317802 0.4150023  0.5095245  0.36478445]\n",
            " [0.45317802 0.4150023  0.5095245  0.36478445]\n",
            " [0.5227884  0.44142115 0.47519785 0.6189315 ]\n",
            " [0.44527724 0.52482957 0.5381678  0.55754733]\n",
            " [0.41440958 0.44209144 0.53455067 0.41253546]]\n",
            "Predictions (First 5 Rows):\n",
            " [[0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [1 0 0 1]\n",
            " [0 1 1 1]\n",
            " [0 0 1 0]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "Logits Distribution (mean ± std): -0.122096725 ± 0.4047456\n",
            "Logits (First 5 Rows):\n",
            " [[-0.37611493 -0.2905845   0.07422741 -0.8892134 ]\n",
            " [-0.37611493 -0.2905845   0.07422741 -0.8892134 ]\n",
            " [ 0.07076176 -0.411063   -0.16415098  0.48841953]\n",
            " [-0.2238619  -0.03346446  0.11986926  0.21398996]\n",
            " [-0.4849691  -0.24332261  0.16072911 -0.67808414]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.4070643  0.4278608  0.51854837 0.2912722 ]\n",
            " [0.4070643  0.4278608  0.51854837 0.2912722 ]\n",
            " [0.5176831  0.39865726 0.4590541  0.619734  ]\n",
            " [0.44426706 0.49163467 0.5299315  0.5532943 ]\n",
            " [0.38107944 0.4394677  0.540096   0.33668905]]\n",
            "Predictions (First 5 Rows):\n",
            " [[0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [1 0 0 1]\n",
            " [0 0 1 1]\n",
            " [0 0 1 0]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=90, training_loss=0.6932483673095703, metrics={'train_runtime': 1280.6582, 'train_samples_per_second': 0.523, 'train_steps_per_second': 0.07, 'total_flos': 44071893166080.0, 'train_loss': 0.6932483673095703, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Evaluation ---\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)\n",
        "\n",
        "# Generate classification report\n",
        "all_preds = trainer.predict(test_dataset).predictions\n",
        "all_labels = [item['labels'].tolist() for item in test_dataset]\n",
        "all_preds = (all_preds > 0.5).astype(int)\n",
        "print(classification_report(all_labels, all_preds, target_names=unique_labels))\n",
        "\n",
        "\n",
        "\n",
        "# --- 8. Save Model & Artifacts ---\n",
        "model.save_pretrained(\"./saved_model\")\n",
        "tokenizer.save_pretrained(\"./saved_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3D9TvTEn6vSY",
        "outputId": "08fceb23-6a18-4fde-a487-b483903899a8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits Distribution (mean ± std): 0.03221993 ± 0.40502295\n",
            "Logits (First 5 Rows):\n",
            " [[ 0.558419   -0.23012756 -0.42872444  0.19110355]\n",
            " [ 0.558419   -0.23012756 -0.42872444  0.19110355]\n",
            " [ 0.59202385 -0.2959283  -0.43018317  0.24730423]\n",
            " [ 0.5644435  -0.2671002  -0.46082866  0.32615334]\n",
            " [ 0.58744705 -0.28118682 -0.4484228   0.21871197]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.6360867  0.44272068 0.39443097 0.547631  ]\n",
            " [0.6360867  0.44272068 0.39443097 0.547631  ]\n",
            " [0.64382935 0.42655316 0.3940826  0.5615129 ]\n",
            " [0.6374801  0.4336191  0.38678926 0.5808231 ]\n",
            " [0.64277923 0.43016288 0.38973582 0.55446106]]\n",
            "Predictions (First 5 Rows):\n",
            " [[1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "{'eval_loss': 0.717995285987854, 'eval_precision': 0.45652173913043476, 'eval_recall': 0.5, 'eval_f1': 0.4772727272727273, 'eval_runtime': 9.6461, 'eval_samples_per_second': 2.384, 'eval_steps_per_second': 0.311, 'epoch': 10.0}\n",
            "Logits Distribution (mean ± std): 0.03221993 ± 0.40502295\n",
            "Logits (First 5 Rows):\n",
            " [[ 0.558419   -0.23012756 -0.42872444  0.19110355]\n",
            " [ 0.558419   -0.23012756 -0.42872444  0.19110355]\n",
            " [ 0.59202385 -0.2959283  -0.43018317  0.24730423]\n",
            " [ 0.5644435  -0.2671002  -0.46082866  0.32615334]\n",
            " [ 0.58744705 -0.28118682 -0.4484228   0.21871197]]\n",
            "Probabilities (First 5 Rows):\n",
            " [[0.6360867  0.44272068 0.39443097 0.547631  ]\n",
            " [0.6360867  0.44272068 0.39443097 0.547631  ]\n",
            " [0.64382935 0.42655316 0.3940826  0.5615129 ]\n",
            " [0.6374801  0.4336191  0.38678926 0.5808231 ]\n",
            " [0.64277923 0.43016288 0.38973582 0.55446106]]\n",
            "Predictions (First 5 Rows):\n",
            " [[1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]\n",
            " [1 0 0 1]]\n",
            "Labels (First 5 Rows):\n",
            " [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [1. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 1.]]\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       Competition       0.43      1.00      0.61        10\n",
            "         Objection       0.00      0.00      0.00        10\n",
            "Pricing Discussion       0.00      0.00      0.00        11\n",
            "          Security       0.00      0.00      0.00        11\n",
            "\n",
            "         micro avg       0.43      0.24      0.31        42\n",
            "         macro avg       0.11      0.25      0.15        42\n",
            "      weighted avg       0.10      0.24      0.14        42\n",
            "       samples avg       0.43      0.25      0.30        42\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./saved_model/tokenizer_config.json',\n",
              " './saved_model/special_tokens_map.json',\n",
              " './saved_model/vocab.txt',\n",
              " './saved_model/added_tokens.json',\n",
              " './saved_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from typing import List\n",
        "\n",
        "# Load the trained model and tokenizer (Task 1 model)\n",
        "model_path = \"/content/saved_model\"  # Replace with your actual model path\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Define the labels used during training\n",
        "labels = [\"Objection\", \"General Query\", \"Competition\", \"Pricing Discussion\"]\n",
        "\n",
        "# Load domain knowledge JSON\n",
        "with open(\"domain_knowledge.json\", \"r\") as f:\n",
        "    domain_knowledge = json.load(f)\n",
        "\n",
        "# Function to classify text (supports single-label classification)\n",
        "def classify_text(text: str, tokenizer, model, labels: List[str]) -> List[str]:\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()  # For single-label classification\n",
        "    return [labels[predicted_class]]\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text: str) -> str:\n",
        "    return text.lower()\n",
        "\n",
        "# Function to extract entities\n",
        "def extract_entities(text: str, domain_knowledge: dict, predicted_labels: List[str]) -> dict:\n",
        "    entities = {}\n",
        "    for label in predicted_labels:\n",
        "        if label in domain_knowledge:\n",
        "            keywords = domain_knowledge[label]\n",
        "            matched_keywords = [keyword for keyword in keywords if keyword in text]\n",
        "            print(f\"Label: {label}, Matched Keywords: {matched_keywords}\")  # Debugging step\n",
        "            entities[f\"{label}_keywords\"] = matched_keywords\n",
        "    return entities\n",
        "\n",
        "# Function to process text data\n",
        "def process_text_data(input_file: str, output_file: str):\n",
        "    # Read input text file\n",
        "    with open(input_file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    results = []\n",
        "    for line in lines:\n",
        "        # Clean the input text\n",
        "        cleaned = clean_text(line.strip())\n",
        "\n",
        "        # Classify the text\n",
        "        predicted_labels = classify_text(cleaned, tokenizer, model, labels)\n",
        "\n",
        "        # Extract entities based on the predicted labels\n",
        "        extracted_entities = extract_entities(cleaned, domain_knowledge, predicted_labels)\n",
        "\n",
        "        # Create the result object\n",
        "        result = {\n",
        "            \"text\": line.strip(),\n",
        "            \"cleaned_text\": cleaned,\n",
        "            \"predicted_labels\": predicted_labels,\n",
        "            \"extracted_entities\": extracted_entities,\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    # Write the results to a JSON file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "\n",
        "# Example usage\n",
        "input_file = \"/content/sample_data/input.txt\"  # Replace with your input .txt file path\n",
        "output_file = \"/content/sample_data/output.json\"  # Replace with your desired output file path\n",
        "process_text_data(input_file, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n0GV4IRCBVB",
        "outputId": "1ab99ade-1677-4c9f-8843-ccd48466d225"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: Objection, Matched Keywords: ['concern', 'pricing']\n",
            "Label: Objection, Matched Keywords: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# --- Load Domain Knowledge ---\n",
        "with open('domain_knowledge.json', 'r') as f:\n",
        "    domain_knowledge = json.load(f)\n",
        "\n",
        "# --- 5. Load Pretrained Model ---\n",
        "model_name = \"/content/saved_model\"  # Replace with your model path or name\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# --- 6. Text Preprocessing ---\n",
        "def preprocess_text(text):\n",
        "    # Add any text preprocessing steps here like lowercasing, removing special characters, etc.\n",
        "    return text.lower()\n",
        "\n",
        "# --- 7. Entity Extraction ---\n",
        "def extract_entities(text, domain_knowledge):\n",
        "    entities = {\n",
        "        'competitors': [],\n",
        "        'features': [],\n",
        "        'pricing_keywords': [],\n",
        "        'priority': 'General extraction'  # Default to 'General extraction'\n",
        "    }\n",
        "\n",
        "    # Extract competitors\n",
        "    for competitor in domain_knowledge['competitors']:\n",
        "        if re.search(r'\\b' + re.escape(competitor.lower()) + r'\\b', text):\n",
        "            entities['competitors'].append(competitor)\n",
        "\n",
        "    # Extract features\n",
        "    for feature in domain_knowledge['features']:\n",
        "        if re.search(r'\\b' + re.escape(feature.lower()) + r'\\b', text):\n",
        "            entities['features'].append(feature)\n",
        "\n",
        "    # Extract pricing-related terms\n",
        "    for pricing_term in domain_knowledge['pricing_keywords']:\n",
        "        if re.search(r'\\b' + re.escape(pricing_term.lower()) + r'\\b', text):\n",
        "            entities['pricing_keywords'].append(pricing_term)\n",
        "\n",
        "    return entities\n",
        "\n",
        "# --- 8. Model Prediction ---\n",
        "def predict_labels(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "    return predicted_class  # Return the predicted class index (or you can map it to label)\n",
        "\n",
        "# --- 9. Example Text Data ---\n",
        "input_text = \"Your competitor CompetitorX offers better services with AI engine at a lower cost. The discount they offer is better than ours.\"\n",
        "\n",
        "# --- Preprocessing ---\n",
        "cleaned_text = preprocess_text(input_text)\n",
        "\n",
        "# --- Entity Extraction ---\n",
        "extracted_entities = extract_entities(cleaned_text, domain_knowledge)\n",
        "\n",
        "# --- Prediction ---\n",
        "predicted_label_index = predict_labels(cleaned_text)\n",
        "\n",
        "# Map predicted index to actual label (you need to define the mapping)\n",
        "label_mapping = {0: \"Objection\", 1: \"General Query\"}  # Update with your actual label mapping\n",
        "predicted_labels = [label_mapping.get(predicted_label_index, \"Unknown\")]\n",
        "\n",
        "# --- Output ---\n",
        "output = {\n",
        "    'text': input_text,\n",
        "    'cleaned_text': cleaned_text,\n",
        "    'predicted_labels': predicted_labels,  # Using the model's prediction\n",
        "    'extracted_entities': extracted_entities\n",
        "}\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDQUDII2DePt",
        "outputId": "5efeee75-deef-4cbd-a74a-f84502ee51ec"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'Your competitor CompetitorX offers better services with AI engine at a lower cost. The discount they offer is better than ours.', 'cleaned_text': 'your competitor competitorx offers better services with ai engine at a lower cost. the discount they offer is better than ours.', 'predicted_labels': ['Objection'], 'extracted_entities': {'competitors': ['CompetitorX'], 'features': ['AI engine'], 'pricing_keywords': ['discount'], 'priority': 'General extraction'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi[all] uvicorn pyngrok transformers torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jmicaR5F9Du",
        "outputId": "0a80e3a4-6d87-4cbd-b611-0085c7c64cc5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Collecting fastapi[all]\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi[all])\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (2.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (4.12.2)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all])\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (3.1.5)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[all])\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: itsdangerous>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (2.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (6.0.2)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi[all])\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: orjson>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (3.10.15)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[all])\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings>=2.0.0 (from fastapi[all])\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pydantic-extra-types>=2.0.0 (from fastapi[all])\n",
            "  Downloading pydantic_extra_types-2.10.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[all])\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[all]) (3.10)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (0.15.1)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all])\n",
            "  Downloading rich_toolkit-0.13.2-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[all]) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[all]) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[all]) (1.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.1.5->fastapi[all]) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.0.0->fastapi[all])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all]) (14.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->fastapi[all]) (1.3.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (0.1.2)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading pydantic_extra_types-2.10.2-py3-none-any.whl (35 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading rich_toolkit-0.13.2-py3-none-any.whl (13 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvloop, uvicorn, ujson, python-multipart, python-dotenv, pyngrok, httptools, dnspython, watchfiles, starlette, email-validator, rich-toolkit, pydantic-settings, pydantic-extra-types, fastapi, fastapi-cli\n",
            "Successfully installed dnspython-2.7.0 email-validator-2.2.0 fastapi-0.115.7 fastapi-cli-0.0.7 httptools-0.6.4 pydantic-extra-types-2.10.2 pydantic-settings-2.7.1 pyngrok-7.2.3 python-dotenv-1.0.1 python-multipart-0.0.20 rich-toolkit-0.13.2 starlette-0.45.3 ujson-5.10.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import json\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load model (Task 1 model path)\n",
        "def load_model(model_path=\"./saved_model\"):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    return tokenizer, model\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Load the model and tokenizer\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "# Load domain knowledge\n",
        "with open('domain_knowledge.json', 'r') as f:\n",
        "    domain_knowledge = json.load(f)\n",
        "\n",
        "# Text input model\n",
        "class TextInput(BaseModel):\n",
        "    text: str\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "# Entity extraction function\n",
        "def extract_entities(text, domain_knowledge):\n",
        "    entities = {\n",
        "        'competitors': [],\n",
        "        'features': [],\n",
        "        'pricing_keywords': [],\n",
        "        'priority': 'General extraction'\n",
        "    }\n",
        "\n",
        "    for competitor in domain_knowledge['competitors']:\n",
        "        if re.search(r'\\b' + re.escape(competitor.lower()) + r'\\b', text):\n",
        "            entities['competitors'].append(competitor)\n",
        "\n",
        "    for feature in domain_knowledge['features']:\n",
        "        if re.search(r'\\b' + re.escape(feature.lower()) + r'\\b', text):\n",
        "            entities['features'].append(feature)\n",
        "\n",
        "    for pricing_term in domain_knowledge['pricing_keywords']:\n",
        "        if re.search(r'\\b' + re.escape(pricing_term.lower()) + r'\\b', text):\n",
        "            entities['pricing_keywords'].append(pricing_term)\n",
        "\n",
        "    return entities\n",
        "\n",
        "# Define the FastAPI endpoint\n",
        "@app.post(\"/process_text/\")\n",
        "async def process_text(input_data: TextInput):\n",
        "    input_text = input_data.text\n",
        "\n",
        "    # Preprocess the text\n",
        "    cleaned_text = preprocess_text(input_text)\n",
        "\n",
        "    # Extract entities\n",
        "    extracted_entities = extract_entities(cleaned_text, domain_knowledge)\n",
        "\n",
        "    # Generate summary (simple version)\n",
        "    summary = f\"Competitor offers better services with {', '.join(extracted_entities['features'])}.\"\n",
        "\n",
        "    # Predicted labels (dummy for now, replace with actual model prediction)\n",
        "    predicted_labels = [\"Objection\"]  # Replace this with the actual model prediction\n",
        "\n",
        "    return {\n",
        "        \"text\": input_text,\n",
        "        \"cleaned_text\": cleaned_text,\n",
        "        \"predicted_labels\": predicted_labels,\n",
        "        \"extracted_entities\": extracted_entities,\n",
        "        \"summary\": summary\n",
        "    }\n"
      ],
      "metadata": {
        "id": "VVUVEY22GCR-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlA3htPcH0XK",
        "outputId": "4bd7890b-ada9-4a31-d251-58838f10e781"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ycsPAssH0Zw",
        "outputId": "122cbd31-39da-42b1-c68a-cf6614164ef3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.7)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.45.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.46.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify, request\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import json\n",
        "import re\n",
        "\n",
        "# --- Load Domain Knowledge ---\n",
        "with open('domain_knowledge.json', 'r') as f:\n",
        "    domain_knowledge = json.load(f)\n",
        "\n",
        "# --- Load Task 1 Model ---\n",
        "def load_model(model_path=\"/content/saved_model\"):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    return tokenizer, model\n",
        "\n",
        "# Load model\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "# --- Flask App Setup ---\n",
        "app = Flask(__name__)\n",
        "\n",
        "# --- Text Preprocessing Function ---\n",
        "def preprocess_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "# --- Entity Extraction Function ---\n",
        "def extract_entities(text, domain_knowledge):\n",
        "    entities = {\n",
        "        'competitors': [],\n",
        "        'features': [],\n",
        "        'pricing_keywords': [],\n",
        "        'priority': 'General extraction'  # Default to 'General extraction'\n",
        "    }\n",
        "\n",
        "    # Extract competitors\n",
        "    for competitor in domain_knowledge['competitors']:\n",
        "        if re.search(r'\\b' + re.escape(competitor.lower()) + r'\\b', text):\n",
        "            entities['competitors'].append(competitor)\n",
        "\n",
        "    # Extract features\n",
        "    for feature in domain_knowledge['features']:\n",
        "        if re.search(r'\\b' + re.escape(feature.lower()) + r'\\b', text):\n",
        "            entities['features'].append(feature)\n",
        "\n",
        "    # Extract pricing-related terms\n",
        "    for pricing_term in domain_knowledge['pricing_keywords']:\n",
        "        if re.search(r'\\b' + re.escape(pricing_term.lower()) + r'\\b', text):\n",
        "            entities['pricing_keywords'].append(pricing_term)\n",
        "\n",
        "    return entities\n",
        "\n",
        "# --- Prediction Function ---\n",
        "def predict_labels(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.sigmoid(outputs.logits).numpy()\n",
        "\n",
        "    # You can customize the threshold for multi-label classification\n",
        "    predicted_labels = ['Objection' if p[0] > 0.5 else 'General Query' for p in predictions]\n",
        "    return predicted_labels\n",
        "\n",
        "# --- Define the API Endpoint ---\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    # Get the input JSON data\n",
        "    data = request.get_json()\n",
        "    text = data['text']  # Assuming input JSON has a 'text' field\n",
        "\n",
        "    # --- Preprocess the Text ---\n",
        "    cleaned_text = preprocess_text(text)\n",
        "\n",
        "    # --- Entity Extraction ---\n",
        "    extracted_entities = extract_entities(cleaned_text, domain_knowledge)\n",
        "\n",
        "    # --- Predicted Labels ---\n",
        "    predicted_labels = predict_labels(cleaned_text)\n",
        "\n",
        "    # --- Summary (dummy implementation) ---\n",
        "    summary = f\"Text contains references to competitors {extracted_entities['competitors']} with features {extracted_entities['features']}.\"\n",
        "\n",
        "    # --- Return the JSON response ---\n",
        "    response = {\n",
        "        'text': text,\n",
        "        'cleaned_text': cleaned_text,\n",
        "        'predicted_labels': predicted_labels,\n",
        "        'extracted_entities': extracted_entities,\n",
        "        'summary': summary\n",
        "    }\n",
        "    return jsonify(response)\n",
        "\n",
        "# --- Run the Flask App ---\n",
        "if __name__ == \"__main__\":\n",
        "    from google.colab.output import eval_js\n",
        "\n",
        "    # Start the Flask app\n",
        "    app.run(host='0.0.0.0', port=8000)\n",
        "\n",
        "    # Display the API endpoint within Colab using an iframe\n",
        "    eval_js('google.colab.output.iframe(\"http://127.0.0.1:8000\", width=800, height=600)')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcNCKxyFH0dM",
        "outputId": "d9ada331-9afa-4a33-93b0-a200e7a5d19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:8000\n",
            " * Running on http://172.28.0.12:8000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set up a tunnel to the FastAPI app (default port 8000)\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"FastAPI app is running at: {public_url}\")\n",
        "\n",
        "# Run the FastAPI app with Uvicorn\n",
        "!uvicorn app:app --host 0.0.0.0 --port 8000 --reload &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "PEAhcVUeGKRy",
        "outputId": "b6584fbf-7818-4f76-dae0-992b07c3635b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-01-26T19:31:12+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-01-26T19:31:12+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-01-26T19:31:12+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "CRITICAL:pyngrok.process.ngrok:t=2025-01-26T19:31:12+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8674c03d2ed3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Set up a tunnel to the FastAPI app (default port 8000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"FastAPI app is running at: {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    429\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import json\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load Task 1 model\n",
        "def load_model(model_path=\"./saved_model\"):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    return tokenizer, model\n",
        "\n",
        "# Classify text using Task 1 model\n",
        "def classify_text(text, tokenizer, model, labels):\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoding)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.sigmoid(logits)\n",
        "        predictions = (probabilities > 0.5).squeeze().numpy()\n",
        "    return [labels[i] for i, p in enumerate(predictions) if p == 1]\n",
        "\n",
        "# Extract entities from text using domain knowledge\n",
        "def extract_entities(text, domain_knowledge, context_labels):\n",
        "    extracted_entities = {category: [] for category in domain_knowledge.keys()}\n",
        "\n",
        "    # Extract keywords using domain knowledge\n",
        "    for category, keywords in domain_knowledge.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword.lower() in text.lower():\n",
        "                extracted_entities[category].append(keyword)\n",
        "\n",
        "    # Add context-based prioritization\n",
        "    if \"Pricing Discussion\" in context_labels:\n",
        "        extracted_entities[\"priority\"] = \"Focus on pricing-related terms\"\n",
        "    elif \"Competition\" in context_labels:\n",
        "        extracted_entities[\"priority\"] = \"Focus on competitor-related terms\"\n",
        "    else:\n",
        "        extracted_entities[\"priority\"] = \"General extraction\"\n",
        "\n",
        "    return extracted_entities\n",
        "\n",
        "# Main Task 2 Pipeline\n",
        "def task2_pipeline(data_path, domain_knowledge_path, model_path):\n",
        "    # Step 1: Load Data\n",
        "    df = pd.read_csv(data_path)\n",
        "    df[\"cleaned_text\"] = df[\"text\"].str.strip().str.lower()\n",
        "\n",
        "    # Step 2: Load Task 1 model and domain knowledge\n",
        "    tokenizer, model = load_model(model_path)\n",
        "    with open(domain_knowledge_path, 'r') as f:\n",
        "        domain_knowledge = json.load(f)\n",
        "\n",
        "    # Define labels for Task 1 model (used during training)\n",
        "    labels = [\"Objection\", \"Pricing Discussion\", \"Competition\", \"General Query\"]\n",
        "\n",
        "    # Step 3: Process each text snippet\n",
        "    df[\"predicted_labels\"] = df[\"cleaned_text\"].apply(lambda x: classify_text(x, tokenizer, model, labels))\n",
        "    df[\"extracted_entities\"] = df.apply(\n",
        "        lambda row: extract_entities(row[\"cleaned_text\"], domain_knowledge, row[\"predicted_labels\"]),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "# Evaluate precision and recall (if ground truth is available)\n",
        "def evaluate_extraction(predicted_entities, true_entities):\n",
        "    from sklearn.metrics import precision_score, recall_score\n",
        "    y_true = true_entities\n",
        "    y_pred = predicted_entities\n",
        "    precision = precision_score(y_true, y_pred, average=\"micro\")\n",
        "    recall = recall_score(y_true, y_pred, average=\"micro\")\n",
        "    return {\"precision\": precision, \"recall\": recall}\n",
        "\n",
        "# Save Results\n",
        "def save_results(df, output_path):\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Results saved to {output_path}\")\n",
        "\n",
        "# Run Task 2 Pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    data_path = \"/content/sample_data/data.csv\"  # Input file containing text snippets\n",
        "    domain_knowledge_path = \"/content/domain_knowledge.json\"  # Domain-specific keywords\n",
        "    model_path = \"/content/saved_model\"  # Path to the Task 1 trained model\n",
        "    output_path = \"/content/sample_data/task2_results.csv\"  # Path to save the results\n",
        "\n",
        "    # Run the pipeline\n",
        "    results_df = task2_pipeline(data_path, domain_knowledge_path, model_path)\n",
        "    save_results(results_df, output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwRmTR47_SM8",
        "outputId": "73ffc84f-fa61-4b7a-b49c-d6f1951e9b80"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to /content/sample_data/task2_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7arC1A6VF5vb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}